# Applying Generative Adversarial Networks (GANs)

This project provides implementations and explorations of various Generative Adversarial Network (GAN) architectures. The goal is to offer a clear, well-documented codebase for understanding, training, and experimenting with GANs for image generation tasks.

## üöÄ Features

- **Multiple Architectures**: Implementations of several popular GAN models.
  - Vanilla GAN
  - Deep Convolutional GAN (DCGAN)
  - Conditional GAN (CGAN)
- **Standard Datasets**: Scripts and data loaders for common benchmark datasets.
  - MNIST
  - CIFAR-10
- **Jupyter Notebooks**: Interactive notebooks for step-by-step training and visualization.
- **Modular Code**: Well-structured and reusable components for generators, discriminators, and training loops.

## üõ†Ô∏è Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/your-username/Apply-Generative-Adversarial-Networks-GANs.git
    cd Apply-Generative-Adversarial-Networks-GANs
    ```

2.  **Create and activate a virtual environment (recommended):**
    ```bash
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Install the required dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *(Note: You will need to create a `requirements.txt` file containing libraries like `torch`, `torchvision`, `matplotlib`, `numpy`, etc.)*

## ‚ö° Usage

You can train a model by running the corresponding training script. For example, to train a DCGAN on the MNIST dataset:

```bash
python train_dcgan.py --dataset MNIST --epochs 50 --batch_size 128
```

### Arguments

- `--dataset`: The dataset to use for training (e.g., `MNIST`, `CIFAR10`).
- `--epochs`: The total number of training epochs.
- `--batch_size`: The size of each training batch.

Check the individual training scripts for more model-specific arguments.

Alternatively, you can explore the Jupyter notebooks in the `notebooks/` directory for an interactive experience.

## üß† Models

### Vanilla GAN
The simplest form of a GAN, using fully connected layers for both the generator and the discriminator. A great starting point for understanding the core concepts.

### Deep Convolutional GAN (DCGAN)
An advancement that uses deep convolutional layers (specifically `ConvTranspose2d` in the generator and `Conv2d` in the discriminator) to learn to generate higher-quality images. It introduces key architectural guidelines for stable training.

### Conditional GAN (CGAN)
An extension to GANs that allows for conditional image generation. By providing a class label (or other conditioning information) to both the generator and discriminator, you can control the type of image the GAN produces.

## üñºÔ∏è Generated Examples

Here are some examples of images generated by the DCGAN after training on the MNIST dataset for 50 epochs.

*(Placeholder for generated images grid)*

!MNIST Samples

## ü§ù Contributing

Contributions are welcome! If you'd like to contribute, please follow these steps:

1.  Fork the repository.
2.  Create a new branch (`git checkout -b feature/your-feature-name`).
3.  Make your changes and commit them (`git commit -m 'Add some feature'`).
4.  Push to the branch (`git push origin feature/your-feature-name`).
5.  Open a Pull Request.

Please make sure your code adheres to the existing style and includes documentation where necessary.

## üìÑ License

This project is licensed under the MIT License. See the LICENSE file for details.

